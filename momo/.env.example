# =============================================================================
# Momo Configuration
# =============================================================================
# Copy this file to .env and modify as needed.
# All values shown are defaults - you only need to set what you want to change.
# =============================================================================

# -----------------------------------------------------------------------------
# Server Configuration
# -----------------------------------------------------------------------------
MOMO_HOST=0.0.0.0
MOMO_PORT=3000
# Comma-separated API keys for authentication. Leave empty for no auth.
# MOMO_API_KEYS=key1,key2,key3

# -----------------------------------------------------------------------------
# Database Configuration
# -----------------------------------------------------------------------------
# Local SQLite file (default)
DATABASE_URL=file:momo.db

# Turso/LibSQL remote database
# DATABASE_URL=libsql://your-db.turso.io
# DATABASE_AUTH_TOKEN=your-auth-token

# Local replica for remote database (optional)
# DATABASE_LOCAL_PATH=local-replica.db

# -----------------------------------------------------------------------------
# Embedding Configuration
# -----------------------------------------------------------------------------
# Local embedding model (FastEmbed - no API key needed)
EMBEDDING_MODEL=BAAI/bge-small-en-v1.5
EMBEDDING_DIMENSIONS=384
EMBEDDING_BATCH_SIZE=256

# External embedding API (OpenAI, OpenRouter, Ollama, etc.)
# Format: provider/model-name
# EMBEDDING_MODEL=openai/text-embedding-3-small
# EMBEDDING_MODEL=openrouter/openai/text-embedding-3-small
# EMBEDDING_MODEL=ollama/nomic-embed-text

# API configuration for external providers
# EMBEDDING_API_KEY=sk-your-api-key
# EMBEDDING_BASE_URL=https://api.openai.com/v1
# EMBEDDING_RATE_LIMIT=10
EMBEDDING_TIMEOUT=30
EMBEDDING_MAX_RETRIES=3

# -----------------------------------------------------------------------------
# Processing Configuration
# -----------------------------------------------------------------------------
# Chunk size in tokens
CHUNK_SIZE=512
# Overlap between chunks in tokens
CHUNK_OVERLAP=50
# Maximum content length in bytes (default: 10MB)
MAX_CONTENT_LENGTH=10000000

# -----------------------------------------------------------------------------
# OCR Configuration (Image Text Extraction)
# -----------------------------------------------------------------------------
# Local OCR with Tesseract (default - requires tesseract installed)
OCR_MODEL=local/tesseract

# Cloud OCR providers
# OCR_MODEL=mistral/pixtral-12b
# OCR_MODEL=openai/gpt-4o

# OCR API configuration (for cloud providers)
# OCR_API_KEY=your-api-key
# OCR_BASE_URL=https://api.example.com/v1

# Tesseract language codes (comma-separated)
# See: https://tesseract-ocr.github.io/tessdoc/Data-Files-in-different-versions.html
OCR_LANGUAGES=eng
OCR_TIMEOUT=60

# Image dimension limits (in pixels)
OCR_MAX_DIMENSION=4096
OCR_MIN_DIMENSION=50

# -----------------------------------------------------------------------------
# Audio Transcription Configuration
# -----------------------------------------------------------------------------
# NOTE: Audio transcription is partially implemented (Phase 2).
# Local transcription requires whisper.cpp integration.

# Local transcription with Whisper (default)
TRANSCRIPTION_MODEL=local/whisper-small

# Cloud transcription providers
# TRANSCRIPTION_MODEL=openai/whisper-1

# Transcription API configuration
# TRANSCRIPTION_API_KEY=your-api-key
# TRANSCRIPTION_BASE_URL=https://api.openai.com/v1

# Path to local whisper model file (optional)
# TRANSCRIPTION_MODEL_PATH=/path/to/whisper-small.bin

# Timeout in seconds (default: 5 minutes)
TRANSCRIPTION_TIMEOUT=300
# Maximum file size in bytes (default: 100MB)
TRANSCRIPTION_MAX_FILE_SIZE=104857600
# Maximum audio duration in seconds (default: 2 hours)
TRANSCRIPTION_MAX_DURATION=7200

# -----------------------------------------------------------------------------
# LLM Configuration (for AI-powered features)
# -----------------------------------------------------------------------------
# NOTE: LLM is optional. If not configured, intelligence features are disabled.
# Phase 4+ features (memory extraction, relationships) require LLM.

# Format: provider/model-name
# LLM_MODEL=openai/gpt-4o-mini
# LLM_MODEL=openai/gpt-4o
# LLM_MODEL=openrouter/anthropic/claude-3-5-sonnet
# LLM_MODEL=ollama/llama3.2

# LLM API configuration
# LLM_API_KEY=sk-your-api-key
# LLM_BASE_URL=https://api.openai.com/v1
LLM_TIMEOUT=30
LLM_MAX_RETRIES=3

# -----------------------------------------------------------------------------
# Logging
# -----------------------------------------------------------------------------
# Log levels: error, warn, info, debug, trace
RUST_LOG=momo=info,tower_http=debug
